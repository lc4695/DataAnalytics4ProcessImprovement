---
title: "Assignment 6 Report"
author: "Poorna Kumar Mathialagan and Akhil Patnam"
date: "Submitted on 04/22/2022"
output:
  
  pdf_document: 
    fig_caption: yes
    highlight: pygments
  html_document:
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem - 01: Exploratory Data Analysis & Text Analytics
```{r Problem 01 EDA, echo=FALSE}

getwd()
customercomplaintsraw <- read.csv("Consumer_Complaints.csv", stringsAsFactors = TRUE)

```


```{r Problem 01 Unique and Recurring, echo=FALSE}

issuefreq <- as.data.frame(table(customercomplaintsraw$Issue))
colnames(issuefreq) <- c('Issue','Frequency')
sortissuefreq <- issuefreq[order(issuefreq$Frequency),]
sortissuefreq
```


```{r Problem 01 Cleaning of corpus, echo=FALSE} 

precorpus1 <- subset(customercomplaintsraw,select = c(Complaint.ID,Consumer.complaint.narrative,Date.received))
colnames(precorpus1) <- c("ID","Narrative","Date Received")

precorpus1$Narrative <- gsub("'", "", precorpus1$Narrative) # remove apostrophes
precorpus1$Narrative <- gsub("[[:punct:]]", " ", precorpus1$Narrative)  # replace punctuation with space
precorpus1$Narrative <- gsub("[[:cntrl:]]", " ", precorpus1$Narrative)  # replace control characters with space
precorpus1$Narrative <- gsub("^[[:space:]]+", "", precorpus1$Narrative) # remove whitespace at beginning of documents
precorpus1$Narrative <- gsub("[[:space:]]+$", "", precorpus1$Narrative) # remove whitespace at end of documents
precorpus1$Narrative <- gsub("[^a-zA-Z -]", " ", precorpus1$Narrative) # allows only letters
precorpus1$Narrative <- tolower(precorpus1$Narrative)  # force to lowercase
head(precorpus1$Narrative)

```
##Top Features
```{r Problem 01 Top Features, echo=FALSE}
library(quanteda)
dfm.simple1<- dfm(precorpus1$Narrative,
                 remove = stopwords("english"),
                 verbose=TRUE,
                 stem=FALSE)

topfeatures(dfm.simple1, n=50)


# create a custom dictonary
swlist1 = c("xxxx", "xx","told", "stay", "ask", "also", "can", "said","made",
           "make", "s", "go","use", "since", "tri", "now")

dfm1<- dfm(precorpus1$Narrative,
          remove = c(swlist1,stopwords("english")),
          verbose=TRUE,
          stem=FALSE)

topfeatures(dfm1, n=70)


dfm.stem1<- dfm(precorpus1$Narrative,
               remove = c(swlist1,stopwords("english")),
               verbose=TRUE,
               stem=TRUE)

data.frame(topfeatures(dfm.stem1, n=50))

```
```{r Problem 01 Descending Order of Issues, echo=FALSE}
sortissuefreqdsc <- issuefreq[order(-issuefreq$Frequency),]
head(sortissuefreqdsc)

```
```{r Problem 01 Sentiment Analysis, echo=FALSE}
#Sentiment Analysis
mydict1 <- dictionary(list(negative = c("never","remov*","charge*","late","detriment*", "bad*", "awful*", "terrib*", "horribl*","fraud*","refus*","violat*","delete","dont","didnt","theft","error","negat*"),
                          positive = c("good", "great", "super*", "excellent", "yay","well","right","offer")))

dfm.sentiment1 <- dfm(precorpus1$Narrative, 
                     remove = c(swlist1,stopwords("english")), 
                     verbose=TRUE, 
                     dictionary = mydict1,
                     stem=FALSE)
topfeatures(dfm.sentiment1)
View(dfm.sentiment1)

```
# Problem - 01: Solutions
**1. How many complaints have been generated?**

The total number of complaints received are **257341**.


**2. How many are unique or recurring?**

There is only 1 unique issue i.e **Property was damaged or destroyed property**. The rest are **80** recurring issues.


**3. Using "Consumer.complaint.narrative", what can you say about the type of complaints in this report?**

account	206225			
credit	204217			
report	177010			
payment	124563			
call	110732			
inform	99813			
loan	84634			
receiv	78042			
time	74291			
compani	70885	


**4. What type of product issues & complaints are the most frequent?**

Incorrect information on your report is reported **70248** times.		
Problem with a credit reporting company's investigation into an existing problem is reported	**25844** times.
Attempts to collect debt not owed is reported	**22501**	times.	
Improper use of your report is reported	**13675**	times.	
Managing an account is reported	**13416** times.
Written notification about debt is reported	**12354**	times.


**5. Complete a sentiment analysis for all the types of complaint submissions observed during this year.**

**Negative**: 319378    
**Positive**: 53865

# Problem-02 :  Steve Jobs Commencement Speech

In 2005, Steve Jobs delivered the Standford University commencement speech. The transcripts are available here:

https://raw.githubusercontent.com/jcbonilla/BusinessAnalytics/master/BAData/JobsStandfordSpeech.txt

Using install.packages("readtext") and the function readtext( ), load the .txt file and conduct an analysis of top features, words in context, correlations, and a wordcloud visualization

##Installing Packages
```{r Problem-02 :  Installing Pacakges, echo=FALSE}
#install.packages("tm")
#install.packages("quanteda")
#install.packages("readtext")
library(tm)
library(quanteda)
library(readtext)
```

## Loading the text url

```{r Problem-02 :  Steve Jobs Commencement Speech, echo=FALSE}
Speech_url<- "https://raw.githubusercontent.com/jcbonilla/BusinessAnalytics/master/BAData/JobsStandfordSpeech.txt"

precorpus = readtext(Speech_url) 

```

## Cleaning the file
```{r Problem-02 :  Cleaning the file, echo=FALSE}
dim(precorpus)
names(precorpus)  
head(precorpus)
str(precorpus)
head(precorpus$text)


precorpus$text <- gsub("'", "", precorpus$text) # remove apostrophes
precorpus$text <- gsub("[[:punct:]]", " ", precorpus$text)  # replace punctuation with space
precorpus$text <- gsub("[[:cntrl:]]", " ", precorpus$text)  # replace control characters with space
precorpus$text <- gsub("^[[:space:]]+", "", precorpus$text) # remove whitespace at beginning of documents
precorpus$text <- gsub("[[:space:]]+$", "", precorpus$text) # remove whitespace at end of documents
precorpus$text <- gsub("[^a-zA-Z -]", " ", precorpus$text) # allows only letters
precorpus$text <- tolower(precorpus$text)  # force to lowercase
head(precorpus$text)

```

## Preprocessing
```{r Problem-02 :  Preprocessing, echo=FALSE}
require (quanteda)
help(corpus)
names(precorpus)
speechcorpus<- corpus(precorpus$text)
#explore the corpus
names(speechcorpus)
summary(speechcorpus)  #summary of corpus

#create a corpus with metadata
speechcorpus<- corpus(precorpus$text,
                      docnames=precorpus$doc_id)

names(speechcorpus)  
summary(speechcorpus)  #summary of corpus
```

##Top Features
```{r Problem-02 :  Top Features, echo=FALSE}
dfm.simple<- dfm(speechcorpus,
                 remove = stopwords("english"),
                 verbose=TRUE,
                 stem=FALSE)

topfeatures(dfm.simple, n=50)


# create a custom dictonary
swlist = c("t", "s","go", "stay", "get", "don", "didn", "turn","know",
           "now", "everi", "can", "even", "ve","got","go","make","let",
           "way","put","made","let","thing","like","follow","told")

dfm<- dfm(speechcorpus,
          remove = c(swlist,stopwords("english")),
          verbose=TRUE,
          stem=FALSE)

topfeatures(dfm, n=70)


dfm.stem<- dfm(speechcorpus,
               remove = c(swlist,stopwords("english")),
               verbose=TRUE,
               stem=TRUE)

topfeatures(dfm.stem, n=50)

#update for bigrans using tokens
toks.1<-tokens(speechcorpus)   #creates tokens
toks.2<-tokens_remove(toks.1, stopwords("english"))  #remove stopwords from tokens
toks.3 <-tokens_ngrams(toks.2, n=2) # ngram =2
dfm.ngram2<- dfm(toks.3, verbose=TRUE)

topfeatures(dfm.ngram2, n=50)
```

##Words in Context

```{r Problem-02 :  Words in Context, echo=FALSE}
help("kwic")
kwic(speechcorpus, "life", window = 5)

kwic(speechcorpus , "college", window = 5)

```

##Wordcloud visualization

```{r Problem-02 : WordCloud Visualization , echo=FALSE}
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
dark2 <- brewer.pal(8, "Set1")  
freq<-topfeatures(dfm.stem, n=500)

wordcloud(names(freq),
          freq, max.words=500,
          scale=c(3, .1),
          colors=brewer.pal(8, "Set1"))

```

